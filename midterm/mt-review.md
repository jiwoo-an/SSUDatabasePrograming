<h1>##중간 과제 회고</h1>


<h2>+</h2>
    수업에서 다루지 않았던 kaggle을 이용해 과제를 성공해서 정말 뿌듯하고, 한번 하는 법을 알았으니 앞으로도 프로젝트나 실습을 할 때 캐글을 활용할 수 있어서 기쁘다.
    <br/>
<h2>-</h2>
    큰 고민 없이 캐글에 있는 자료를 데이터셋으로 선택했는데, 데이터베이스에 담기까지 굉장히 많은 고민과 실패가 있었다. 과제를 하루 안에 끝내려고 했는데 캐글데이터를 데이터베이스에 집어넣기까지 이틀이나 걸렸다.(그 이후 웹페이지를 만드는 데에는 4시간밖에 걸리지 않았다.) 수요일에 시작했기에 먼저 성공했거나 실패해서 질문 글을 올린 사람이 없어서 정말 리눅스 서버안에서 캐글 데이터를 설치해서 MariaDB에 넣고 작동시키는 것이 가능한가 하는 의문도 들었다. 매 순간순간 진행이 어려웠지만 3번, 정말 포기하고 샘플 데이터베이스로 바꾸려고 고민한 적이 있었다.
    <br/><br/>
    1. kaggle API를 설치하기 위해서는 sudo pip3 install kaggle 명령어를 사용해야 하는데 이를 위해서 pip을 깔려고 했는데 무엇이 잘못되었는지 pip이 설치되지 않아서 kaggle API 설치 명령어가 작동하지 않았다. 왜 설치가 안되는지 이해도 안가고 설치된 위치도 어딘지 모르겠어서 무작정 pip이 설치 안되는 이유를 검색했더니 sudo apt-get update를 하라고 해서, 얼마전에 업데이트를 했기 때문에 아닌걸 알면서도 뾰족한 수가 없어서 그냥 업데이트했다. 당연히 꽤 많은 시간이 걸렸다. 별 것도 아닌 pip설치부터 막혀서 시간을 허비하자 초조해져서 포기하고 샘플 데이터베이스로 할지 고민했다. 한참 삽질하다가 pip3을 명령어로 입력해보니 입력이 되어서, 그냥 사용했다. 
    pip3을 설치하고 나서 pip명령어로 kaggle을 설치하고 싶어서 무심코 pip도 깔려고 해서 문제가 생긴 것 같다.
    <br/>
    2. 이제 kaggle 내의 데이터 셋을 다운로드 하려 했다. 이를 위해서는 내 계정에서 다운받은 kaggle.json파일이 필요했다. 그런데 이 kaggle.json을 GUI가 없는 상태에서 설치하는 법을 찾을 수 없었다. 계속 키워드를 바꿔가며 자료를 검색해도 전부 GUI가 있는 환경에서 쉽게 kaggle.json을 다운받아서 특정 위치에 쉽게 드래그하는 글이었다.
    VMware Tools로 호스트컴퓨터에서 게스트컴으로 옮기려고 공유파일을 설정하는 등 여러가지 시도를 해 보았지만 이것 또한 GUI가 있는 환경에서 작성된 글밖에 없어서 참고가 불가능했다. 이때 지금 쓰고 있는 GUI가 없는 서버 형태의 리눅스로는 kaggle API로 다운 받는 방법이 없는 것 아닌가싶었고 이 때 두번째로 포기하려했다.
    한참 고민하다가 GUI를 서버OS에 추가로 설치하는 방법을 찾아서 Desktop을 우분투에 추가했다.
    <br/>
    3. kaggle사이트에서 데이터셋을 다운받고, unzip으로 압축해제를 하는 데 까진 성공했다. 그런데 그 압축해제를 한 파일에서 cvn이라는 처음 보는 형태의 파일이 나왔다. sql파일이 아니라서 처음엔 압축해제나 다운로드를 잘못 한 것 아닌가 싶었다. 검색을 조금 해보아도 대부분 "만든 데이터베이스를 cvn에 저장하는 법"이 뜨고, 이것을 어떻게 MariaDB에 넣는 지에 대한 정보는 잘 뜨지 않았다. 잘 찾아보니 mysql에 csv파일의 데이터를 쿼리를 통해 집어넣는 것이 있었는데, 이것은 날짜데이터의 년/월/일 순서때문에 계속 오류가 나서 들어가지 않았다. 이 때 세번째로 캐글 데이터를 다루는 것을 포기하고 샘플 데이터베이스를 사용하려 했다. 그러다가 sql로 바꾸는 사이트https://www.convertcsv.com/csv-to-sql.htm 를 활용하여 cvn을  테이블 생성 및 데이터 입력 명령어가 담긴 sql 파일로 바꿀 수 있어서 드디어 데이터베이스안에 캐글의 데이터를 집어넣을 수 있게 되었다.
    모든 과정에서 자료를 찾아야하다보니 데이터를 집어넣는데에만 이틀이 걸렸다. 중간중간에 다른 과목 강의를 듣거나 아르바이트를 해서 48시간을 다 쏟은 것은 아니지만, 그래도 생각보다 너무 오래 걸렸다.
    <br/><br/>
    또 아쉬운 것은, 테이블 두 개를 조인해서 정보를 출력하고 싶었는데 그렇게 하지 못한 것이다.
    내가 사용한 데이터셋은 하나의 테이블 안에 모든 데이터가 집약되어있어서 추가로 다른 csv 파일을 설치할 필요가 없었고, 그래서 한 가지 테이블 안에서 모든 질의를 해결했다.
    같이 업로드 되어있던 다른 테이블은 모두 한 테이블을 만들기 위해 사용되었던 자료들이었다. 사용한 csv 파일 외에 그나마 의미있었던 다른 파일은 환자 개개인의 정보가 담긴 csv파일이었는데, 이것을 사용하려고 데이터에 대한 정보를 확인해보니 대부분의 확진자 데이터가 나이 불명(89%), 성별 불명(90%)이고 지역마저 불분명한 비율이 높아서(28%) 의미 있는 정보를 뽑으려고 쿼리문을 사용해도 의미가 없다고 판단되어 사용하지 않았다. 아예 다 엎고 캐글에서 다른 데이터를 사용해볼까 싶어서 캐글 사이트를 더 서치해 보기도 했다. 하지만 상당수의 데이터셋이  csv파일이 한 개였기에 처음에 다운받았던 코로나19 관련 데이터를 그대로 사용했다.

<h2>!</h2>
    캐글을 가상머신 속 리눅스에서 다루기 위해서 어떻게 해야할 지를 이번 과제를 통해 배웠다. 이를 순서대로 정리해보았다.<br/>
        1. pip3을 우분투 내에 설치 (sudo apt-get install python3-pip)<br/>
        2. Kaggle API 설치. (pip3 install kaggle)<br/>
        3. GUI가 없는 상태에서 설치하는 법은 찾을 수 없어 DesktopGUI 설치(apt-get install ubuntu-desktop, startx)<br/>
        4. kaggle사이트에 로그인해서 내 계정에서 kaggle.json을 다운받고 리눅스의 특정 위치에 설치(~/.kaggle/kaggle.json).<br/>
        5.  kaggle 사이트에서 API 명령어를 복사하여 데이터셋 다운<br/>
        6. 사용자의 Downloads 폴더에서 다운 받은 것을 unzip으로 압축 해제<br/>
        7. 필요한 cvn을  sql로 바꾸는 사이트https://www.convertcsv.com/csv-to-sql.htm 를 활용하여  테이블 생성 및 데이터 입력 명령어가 담긴 sql 파일로 전환<br/>
        8. CREATE 명령어로 필요한 데이터베이스 생성 (데이터베이스명: CORONA19)<br/>
        9. sql파일을 mysql CORONA19 -uadmin -p /< corona19_data.sql 명령어로 데이터베이스 안에 하나의 테이블로 입력.<br/>